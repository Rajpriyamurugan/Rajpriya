# -*- coding: utf-8 -*-
"""naan mudhalvan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RlAPp_qRDy1ui9Rb8GViBLcFtpf_lfWs
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

"""# 1. loading data"""

df= pd.read_csv('/kaggle/input/drug-discovery-data/DDH Data.csv')
df
# 104 rows × 4 columns
# Compound No., SMILES, pIC50 (IC50 in microM), Unnamed: 3

df = df.drop(labels = 'Unnamed: 3', axis=1)
df

# pIC50 (IC50 in microM) is target data, means the dose amount of compunnds to show effective as a drug.

df.info()

df['pIC50 (IC50 in microM)'].unique()

# 'what does 'BLINDED' mean? anyway remove it.

sum(df['pIC50 (IC50 in microM)']=='BLINDED')
# oops!

df = df[df['pIC50 (IC50 in microM)']!='BLINDED']
df

# load the data with properties

df_property = pd.read_csv('/kaggle/input/drug-discovery-data/DDH Data with Properties.csv')
df_property

# 104 rows × 40 columns

df_property.T

# have SMILES, pIC50 columns

df_property.info()

df_property.describe().T

# has features

"""# 2. merge data frame"""

df = pd.merge(df, df_property, on = 'SMILES', how = 'left')
df
# 94 rows × 42 columns

df.T

"""# 3. Select columns"""

df.info()

df.columns

df = df.drop(['Compound No.', 'pIC50 (IC50 in microM)', 'CID',
       'MolecularFormula', 'InChI', 'InChIKey', 'IUPACName'], axis=1)

df.T

df.info()

df.pIC50.unique()
#

df['pIC50'] = pd.to_numeric(df['pIC50'])

df

df.info()

df = df.dropna(axis=0)
df.info()

"""# 4. EDA"""

df.describe().T

# Charge, IsotopeAtomCount, DefinedAtomStereoCount, UndefinedBondStereoCount, CovalentUnitCount have to remove

df = df.drop(['Charge', 'IsotopeAtomCount', 'DefinedAtomStereoCount',
              'UndefinedBondStereoCount', 'CovalentUnitCount'], axis=1)
df.shape

# correlation chart

corrmat = df.corr()
corrmat = round(corrmat, 2)
corrmat

import plotly.express as px
import plotly.io as pio
pio.renderers.default = "notebook_connected"
corrmat data.corr()
fig = px.imshow(corrmat, text_auto=True, aspect="auto")
fig.show()

"""# 5. data split

"""

target = df['pIC50']
features = df.drop(['SMILES', 'pIC50'], axis=1)
target.shape, features.shape

from sklearn import preprocessing
min_max_scaler = preprocessing.MinMaxScaler()

features_scaled = min_max_scaler.fit_transform(features)
features_scaled

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(features_scaled, target, test_size=0.2, random_state=2212)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""# 6. Pipeline to compare regression models quickly"""

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

num_pipeline = Pipeline(steps=[('impute', SimpleImputer(strategy='mean'))])

def prepare_model(algorithm, X_train, y_train):
    model = Pipeline(steps=[('preprocessing', num_pipeline),('algorithm', algorithm)])
    model.fit(X_train, y_train)
    return model

from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.neighbors import KNeighborsRegressor
import time
from sklearn.metrics import mean_squared_error, mean_absolute_error

algorithms = [RandomForestRegressor(), AdaBoostRegressor(), GradientBoostingRegressor(),
              BaggingRegressor(), SVR(), DecisionTreeRegressor(), ExtraTreeRegressor(),
              LinearRegression(), SGDRegressor(), KNeighborsRegressor()]

names = []
times = []
mses = []
maes = []

for algorithm in algorithms:
    name = type(algorithm).__name__
    names.append(name)
    print(name)
    start_time = time.time()
    model = prepare_model(algorithm, X_train, y_train)
    pred = model.predict(X_test)
    end_time = time.time()
    print(end_time - start_time)
    times.append(end_time - start_time)
    mses.append(mean_squared_error(y_test, pred))
    maes.append(mean_absolute_error(y_test, pred))

"""# 7. Comparing Regression Models"""

results_dict = {'Algorithm': names, 'MSE': mses, 'MAE': maes, 'Time': times}
pd.DataFrame(results_dict).sort_values(by='MSE', ascending=1)

# SVR is the best algorithm

model = prepare_model(SVR(), X_train, y_train)
pred = model.predict(X_test)

sns.regplot(x = pred, y = y_test)

"""# 8. SVM model"""

from sklearn.svm import SVR
svr = SVR()

svr.fit(X_train, y_train)
print(svr.score(X_train, y_train))
print(svr.score(X_test, y_test))

svr_pred = svr.predict(X_test)
svr_mse = mean_squared_error(y_test, svr_pred)
print(svr_mse)

"""# 9. predicted values and real values of target, pIC50"""

pred = model.predict(features_scaled)

sns.regplot(x = pred, y = target)

"""#

# 10. low pIC50 materials
"""

df_sorted = df.sort_values(by = 'pIC50', ascending = True)
df_sorted.T

df_sorted = df_sorted[['SMILES', 'pIC50']]
df_sorted

# install rdkit

!pip install rdkit-pypi

# import Chem library
from rdkit import Chem

# transfor smiles strings to mol rdkit object
df_sorted['mol'] = df['SMILES'].apply(lambda x: Chem.MolFromSmiles(x))

print(type(df_sorted['mol'][0]))

df_sorted.shape
# (91, 3)

from rdkit.Chem import Draw
mols_low_pIC50 = df_sorted['mol'][:20]
mols_low_pIC50

#MolsToGridImage allows to paint a number of molecules at a time
Draw.MolsToGridImage(mols_low_pIC50, molsPerRow=4, useSVG=True,
                     legends=list(df_sorted['SMILES'][:20].values))

# low pIC50 materials means high effective drugs

"""# 11. high pIC50 materials"""

mols_high_pIC50 = df_sorted['mol'][71:]
mols_high_pIC50

#MolsToGridImage allows to paint a number of molecules at a time
Draw.MolsToGridImage(mols_high_pIC50, molsPerRow=4, useSVG=True,
                     legends=list(df_sorted['SMILES'][71:].values))

# high pIC50 materials means less_effective drugs

"""# 12. View it in 3D"""

pip install py3Dmol

import py3Dmol
from ipywidgets import interact,fixed,IntSlider
import ipywidgets

def show3D_molecule(idx, style):
    """
    Show molecule in 3D
    """
    mblock = Chem.MolToMolBlock(df_sorted['mol'].iloc[idx])
    viewer = py3Dmol.view(width=300, height=300)
    viewer.addModel(mblock, 'mol')
    viewer.setStyle({style:{}})
    viewer.rotate(45, "y", animationDuration=1)

    viewer.zoomTo()

    print(f"SMILES notation: {df_sorted['SMILES'].iloc[idx]}\nRotate me!");

    return viewer.show()

interact(show3D_molecule,
         idx=ipywidgets.IntSlider(min=0,max=len(df_sorted["mol"])-1,
                                  step=1, value=3064,
                                  description="Molecule"),
         style=ipywidgets.Dropdown(options=['line', 'stick', 'sphere'],
                                   value='stick',
                                   description='Style:'));

"""# 13. Create features from mol rdkit object transformed from SMILES"""

df_sorted.head()

# AddHs function adds H atoms to a MOL (as Hs in SMILES are usualy ignored)

df_sorted['mol'] = df_sorted['mol'].apply(lambda x: Chem.AddHs(x))

# GetNumAtoms() method returns a general nubmer of all atoms in a molecule

df_sorted['num_of_atoms'] = df_sorted['mol'].apply(lambda x: x.GetNumAtoms())

# GetNumHeavyAtoms() method returns a nubmer of all atoms in a molecule with molecular weight > 1

df_sorted['num_of_heavy_atoms'] = df_sorted['mol'].apply(lambda x: x.GetNumHeavyAtoms())

# We're going to searches patterns and use it for a list of most common atoms only
def number_of_atoms(atom_list, df_sorted):
    for i in atom_list:
        df_sorted['num_of_{}_atoms'.format(i)] = df_sorted['mol'].apply(lambda x: len(x.GetSubstructMatches(Chem.MolFromSmiles(i))))

# We're going to searches patterns and use it for a list of most common atoms only
def number_of_atoms(atom_list, df_sorted):
    for i in atom_list:
        df_sorted['num_of_{}_atoms'.format(i)] = df_sorted['mol'].apply(lambda x: len(x.GetSubstructMatches(Chem.MolFromSmiles(i))))

number_of_atoms(['C', 'O', 'N', 'Cl', 'P', 'Br', 'F'], df_sorted)
from rdkit.Chem import Descriptors
df_sorted['tpsa'] = df_sorted['mol'].apply(lambda x: Descriptors.TPSA(x))
df_sorted['mol_w'] = df_sorted['mol'].apply(lambda x: Descriptors.ExactMolWt(x))
df_sorted['num_valence_electrons'] = df_sorted['mol'].apply(lambda x: Descriptors.NumValenceElectrons(x))
df_sorted['num_heteroatoms'] = df_sorted['mol'].apply(lambda x: Descriptors.NumHeteroatoms(x))

df_sorted.T

# 'SMILES', 'pIC50', 'mol', 'num_of_atoms', 'num_of_heavy_atoms',
# 'num_of_C_atoms', 'num_of_O_atoms', 'num_of_N_atoms', 'num_of_Cl_atoms',
# 'num_of_P_atoms', 'num_of_Br_atoms', 'num_of_F_atoms', 'tpsa', 'mol_w',
# 'num_valence_electrons', 'num_heteroatoms'

df_sorted.describe()

df_sorted = df_sorted.drop(['num_of_P_atoms'], axis=1)



# correlation chart

corrmat_2 = df_sorted.corr()
corrmat_2 = round(corrmat_2, 2)
corrmat_2

fig = px.imshow(corrmat_2, text_auto=True, aspect="auto")
fig.show()

"""# 15. Group pIC50 values into low, medium and high effective"""

fig = px.box(df_sorted, x = "pIC50", points="all", width=600, height=300)
fig.show()

df_sorted['pIC50_Group'] = np.where(df_sorted['pIC50'] >= -0.683, 'Less_Effective',
                                    (np.where(df_sorted['pIC50'] <= -1.587412, 'High_Effective',
                                              'Medium_Effective')))
df_sorted

df_sorted = df_sorted.drop(['SMILES', 'mol'], axis=1)

df_sorted.head()

df_sorted.describe()

sns.pairplot(df_sorted[['pIC50', 'num_of_C_atoms', 'num_of_O_atoms', 'num_of_N_atoms',
                        'num_of_Cl_atoms', 'num_of_Br_atoms', 'num_of_F_atoms']],
             diag_kind='kde', kind='reg')
plt.show()

# features for pIC50_Group

plt.figure(figsize=(8, 8))
ax = sns.pairplot(df_sorted, hue='pIC50_Group')
plt.show()

# features for pIC50_Group

plt.figure(figsize=(8, 8))
ax = sns.pairplot(df_sorted.drop(['pIC50'], axis=1), hue='pIC50_Group')
plt.show()



"""### Any Comments are highly appreciated.

> target data pIC50, the lower concentration means the better effective drug

> IC50 - The half maximal inhibitory concentration (IC50) is a measure of the potency of a substance in inhibiting a specific biological or biochemical function.

> IC50 is a quantitative measure that indicates how much of a particular inhibitory substance (e.g. drug) is needed to inhibit, in vitro, a given biological process or biological component by 50%.

> The biological component could be an enzyme, cell, cell receptor or microorganism. IC50 values are typically expressed as molar concentration.
"""



"""### ref. Linear Regression Model"""

from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.metrics import mean_squared_error
lr = LinearRegression()

lr.fit(X_train, y_train)
print(lr.score(X_train, y_train))
print(lr.score(X_test, y_test))

lr_pred = lr.predict(X_test)
lr_mse = mean_squared_error(y_test, lr_pred)
print(lr_mse)

print(lr.intercept_)
print(lr.coef_)

# scatter plot

sns.regplot(x = lr_pred, y = y_test)

"""### ref. Lasso Linear Regression Model"""

ls = Lasso()

ls.fit(X_train, y_train)
print(ls.score(X_train, y_train))
print(ls.score(X_test, y_test))

ls_pred = ls.predict(X_test)
ls_mse = mean_squared_error(y_test, ls_pred)
print(ls_mse)

from sklearn.model_selection import GridSearchCV # to find hyperparameter

params = {'alpha' :  [0.01, 0.1, 1, 10, 100, 1000]}
grid = GridSearchCV(ls, param_grid = params, scoring = 'neg_mean_squared_error', cv = 5)
grid.fit(X_train, y_train)
grid.best_score_, grid.best_params_

# Lasso Regression with optimized hyperparameter

ls_o = Lasso(alpha = 0.01)

ls_o.fit(X_train, y_train)
print(ls_o.score(X_train, y_train))
print(ls_o.score(X_test, y_test))

ls_o_pred = ls_o.predict(X_test)
ls_o_mse = mean_squared_error(y_test, ls_o_pred)
print(ls_o_mse)

"""### ref. Ridge"""

# Ridge
ri = Ridge()
ri.fit(X_train, y_train)
print(ri.score(X_train, y_train))
print(ri.score(X_test, y_test))

ri_pred = ri.predict(X_test)
ri_mse = mean_squared_error(y_test, ri_pred)
print(ri_mse)

"""### ref. KNeighbors Regression"""

from sklearn.neighbors import KNeighborsRegressor
knr = KNeighborsRegressor()

knr.fit(X_train, y_train)
print(knr.score(X_train, y_train))
print(knr.score(X_test, y_test))

knr_pred = knr.predict(X_test)
knr_mse = mean_squared_error(y_test, knr_pred)
print(knr_mse)

"""### ref. DecisionTreeRegressor"""

from sklearn.tree import DecisionTreeRegressor
dtr = DecisionTreeRegressor(random_state=2212)

dtr.fit(X_train, y_train)
print(dtr.score(X_train, y_train))
print(dtr.score(X_test, y_test))

dtr_pred = dtr.predict(X_test)
dtr_mse = mean_squared_error(y_test, dtr_pred)
print(dtr_mse)

# overfitting

from sklearn.ensemble import RandomForestRegressor
rfr = RandomForestRegressor(random_state=2207, n_estimators=100)

rfr.fit(X_train, y_train)
print(rfr.score(X_train, y_train))
print(rfr.score(X_test, y_test))

rfr_pred = rfr.predict(X_test)
rfr_mse = mean_squared_error(y_test, rfr_pred)
print(dtr_mse)

"""### ref. xgboost"""

import xgboost as xgb

xgr = xgb.XGBRegressor(random_state=2212)
xgr.fit(X_train, y_train)

print(xgr.score(X_train, y_train))
print(xgr.score(X_test, y_test))

xgr_pred = xgr.predict(X_test)
xgr_mse = mean_squared_error(y_test, xgr_pred)
print(xgr_mse)

"""### ref. Ridge Regression"""

from sklearn.linear_model import Ridge

regression = Ridge(alpha=0.5)
model_ri = regression.fit(X_train, y_train)
model_ri

from sklearn.linear_model import RidgeCV
ri_cv = RidgeCV(alphas=[0.1, 1.0, 10.0])

model_ri_cv = ri_cv.fit(X_train, y_train)

print(model_ri_cv.intercept_)
print(model_ri_cv.coef_)

# predict values in test dataset

predicted_pIC50 = model_ri_cv.predict(X_test)

# scatter plot

sns.regplot(x = predicted_pIC50, y = y_test)

mean_squared_error(np.array(y_test), predicted_pIC50)